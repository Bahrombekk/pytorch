{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/W/Bm2GiqDLLM0/8kNPR0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bahrombekk/pytorch/blob/main/Data_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o8clW6w6xcOp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader,random_split\n",
        "import torch.nn.functional as F\n",
        "import glob\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "# from torchinfo import summary\n",
        "from torchsummary import summary\n",
        "import pathlib\n",
        "from PIL import Image\n",
        "from torchvision.transforms import transforms\n",
        "from torch.optim import Adam\n",
        "\n",
        "import torchvision.transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hnVo-xfxeYq",
        "outputId": "16c76950-02f2-4d2f-e307-8cb7fae25f7e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -O dataset.zip https://www.dropbox.com/s/e5f4epncmydijrw/Komp_in_tel.zip?dl=0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TngDOzw5xjhe",
        "outputId": "1e512d15-b9bf-4bb9-e8a2-3a82d1642e4c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-09 16:38:38--  https://www.dropbox.com/s/e5f4epncmydijrw/Komp_in_tel.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.71.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.71.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/e5f4epncmydijrw/Komp_in_tel.zip [following]\n",
            "--2023-07-09 16:38:38--  https://www.dropbox.com/s/raw/e5f4epncmydijrw/Komp_in_tel.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc24a0f1a2652a6206f02413f273.dl.dropboxusercontent.com/cd/0/inline/B_j4B7cZA4JpwvNP_dEz1SInk6zyJ_FRCj5Q864Qdcgx_MgNOm-0TyS-n3i-_g5UJpQJCKMEOAicWQGTDRF2fkuvbXXWUOE_Qz-mJEMkVXeWt87Iy61JGcRnbYNWoOCUobZqvXYV-3-k9pnMHLQQIjehhFHAh7TLG3dnwN0-2K4tmw/file# [following]\n",
            "--2023-07-09 16:38:39--  https://uc24a0f1a2652a6206f02413f273.dl.dropboxusercontent.com/cd/0/inline/B_j4B7cZA4JpwvNP_dEz1SInk6zyJ_FRCj5Q864Qdcgx_MgNOm-0TyS-n3i-_g5UJpQJCKMEOAicWQGTDRF2fkuvbXXWUOE_Qz-mJEMkVXeWt87Iy61JGcRnbYNWoOCUobZqvXYV-3-k9pnMHLQQIjehhFHAh7TLG3dnwN0-2K4tmw/file\n",
            "Resolving uc24a0f1a2652a6206f02413f273.dl.dropboxusercontent.com (uc24a0f1a2652a6206f02413f273.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6021:15::a27d:410f\n",
            "Connecting to uc24a0f1a2652a6206f02413f273.dl.dropboxusercontent.com (uc24a0f1a2652a6206f02413f273.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B_jB-XC-cAhgPUZFq5DgxQSl1SeKgTywvXbeiUKmE7NM6rNDeYh2QfjvTR4oZ03XcPH0dHNMSoR3ab5mGJxNQEeIBeXhih-qj_E3LhkFJ_VLmUgwpXhClVnXA08YZ-Ms9BQnvHcxa8I5QG6McIF6763wiIyNP2bAdFdi61POkZblrZNgfO-2pXxZnoND61XNiJkbM_XzbqnysDEVr5Q5zn8xH--wLdqyocAfIa1ck8Grc_P7_AYeRiLuHA6WhuT4v_O2Q_CjC5vXXwUJ-UtAhv-NeoARx2jrJvQgZfx_jAtpb-3sTeedn2AWngEcqEg1iRN5L_E8ZioNia_GNgbpfO58kUu05qBiz8S8y-CLqs9xSmxU2ZYQxMhxWTXyfpmz28CeBwq7UYS0MdGXUE8U_vZluTIUHqJYSeVs5MlOfYNjng/file [following]\n",
            "--2023-07-09 16:38:39--  https://uc24a0f1a2652a6206f02413f273.dl.dropboxusercontent.com/cd/0/inline2/B_jB-XC-cAhgPUZFq5DgxQSl1SeKgTywvXbeiUKmE7NM6rNDeYh2QfjvTR4oZ03XcPH0dHNMSoR3ab5mGJxNQEeIBeXhih-qj_E3LhkFJ_VLmUgwpXhClVnXA08YZ-Ms9BQnvHcxa8I5QG6McIF6763wiIyNP2bAdFdi61POkZblrZNgfO-2pXxZnoND61XNiJkbM_XzbqnysDEVr5Q5zn8xH--wLdqyocAfIa1ck8Grc_P7_AYeRiLuHA6WhuT4v_O2Q_CjC5vXXwUJ-UtAhv-NeoARx2jrJvQgZfx_jAtpb-3sTeedn2AWngEcqEg1iRN5L_E8ZioNia_GNgbpfO58kUu05qBiz8S8y-CLqs9xSmxU2ZYQxMhxWTXyfpmz28CeBwq7UYS0MdGXUE8U_vZluTIUHqJYSeVs5MlOfYNjng/file\n",
            "Reusing existing connection to uc24a0f1a2652a6206f02413f273.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1525693 (1.5M) [application/zip]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip         100%[===================>]   1.45M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-07-09 16:38:40 (12.0 MB/s) - ‘dataset.zip’ saved [1525693/1525693]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset.zip"
      ],
      "metadata": {
        "id": "WyA0sJEVxmsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "uzXp7Xw3xpvE"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Compose([\n",
        "    T.Resize(size=(150,150)),\n",
        "    T.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "Rlmw35C7xrtm"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KOMP_in_tel_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, path, transform = None):\n",
        "        # int for cross entryp loss\n",
        "        self.path_list = list(path.glob('*/*.jpg'))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        img = Image.open(self.path_list[index])\n",
        "        label = (self.path_list[index]).parts[-2]\n",
        "        label = 0 if 'kompiyuter' in label else 1\n",
        "        if transform != None:\n",
        "            img = transform(img)\n",
        "\n",
        "        return img, int(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.path_list)"
      ],
      "metadata": {
        "id": "YGFfUzeIxt_s"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = pathlib.Path('/content/Komp_in_tel/train')\n",
        "test_path = pathlib.Path('/content/Komp_in_tel/validation')"
      ],
      "metadata": {
        "id": "X7CNq4uOxwg6"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = KOMP_in_tel_Dataset(train_path, transform)\n",
        "test_dataset = KOMP_in_tel_Dataset(test_path, transform)"
      ],
      "metadata": {
        "id": "h3BnAV1YxzQf"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_list = list(train_path.glob('*/*.jpg'))\n",
        "path_test=list(test_path.glob('*/*.jpg'))"
      ],
      "metadata": {
        "id": "DBTR8rRdx2eg"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
        "test_data = DataLoader(test_dataset, batch_size=10, shuffle=True)"
      ],
      "metadata": {
        "id": "4XGcRylJx4mA"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self,num_classes=2):\n",
        "        super(ConvNet,self).__init__()\n",
        "\n",
        "        #Output size after convolution filter\n",
        "        #((w-f+2P)/s) +1\n",
        "\n",
        "        #Input shape= (256,3,150,150)\n",
        "\n",
        "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,12,150,150)\n",
        "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
        "        #Shape= (256,12,150,150)\n",
        "        self.relu1=nn.ReLU()\n",
        "        #Shape= (256,12,150,150)\n",
        "\n",
        "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
        "        #Reduce the image size be factor 2\n",
        "        #Shape= (256,12,75,75)\n",
        "\n",
        "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,20,75,75)\n",
        "        self.relu2=nn.ReLU()\n",
        "        #Shape= (256,20,75,75)\n",
        "\n",
        "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,32,75,75)\n",
        "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
        "        #Shape= (256,32,75,75)\n",
        "        self.relu3=nn.ReLU()\n",
        "        #Shape= (256,32,75,75)\n",
        "\n",
        "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
        "\n",
        "        #Feed forwad function\n",
        "\n",
        "    def forward(self,input):\n",
        "        output=self.conv1(input)\n",
        "        output=self.bn1(output)\n",
        "        output=self.relu1(output)\n",
        "\n",
        "        output=self.pool(output)\n",
        "\n",
        "        output=self.conv2(output)\n",
        "        output=self.relu2(output)\n",
        "\n",
        "        output=self.conv3(output)\n",
        "        output=self.bn3(output)\n",
        "        output=self.relu3(output)\n",
        "\n",
        "        #Above output will be in matrix form, with shape (256,32,75,75)\n",
        "\n",
        "        output=output.view(-1,32*75*75)\n",
        "\n",
        "        output=self.fc(output)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "D9VmiQWPx7MS"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=ConvNet()"
      ],
      "metadata": {
        "id": "vQrWdwHtx9Cj"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "zeOD66KsyAGI"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5"
      ],
      "metadata": {
        "id": "gCcbdCj2yCWM"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, train_dataloader, test_dataloader, criterion, optimizer, epochs=3):\n",
        "        self.model = model\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.test_dataloader = test_dataloader\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        self.epochs = epochs\n",
        "        self.history = {'loss':[],'acc':[],'val_loss':[],'val_acc':[]}\n",
        "\n",
        "    def train_loop(self):\n",
        "        sum_loss = 0\n",
        "        sum_accuracy = 0\n",
        "        n = len(self.train_dataloader)\n",
        "        for i, (data,label) in enumerate(tqdm(self.train_dataloader)):\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "            # prediction model\n",
        "            output = self.model(data)\n",
        "            # find loss\n",
        "            loss = self.criterion(output, label)\n",
        "\n",
        "            sum_loss += loss.item()\n",
        "            n_corrects = (output.argmax(axis=1)==label).sum().item()\n",
        "            sum_accuracy += n_corrects/label.size(0)\n",
        "\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        train_loss = sum_loss/n\n",
        "        train_accuracy = sum_accuracy/n\n",
        "\n",
        "        self.history['loss'].append(train_loss)\n",
        "        self.history['acc'].append(train_accuracy)\n",
        "\n",
        "        return train_loss, train_accuracy\n",
        "\n",
        "    def validation_loop(self):\n",
        "        sum_loss = 0\n",
        "        sum_accuracy = 0\n",
        "        n = len(self.test_dataloader)\n",
        "        for i, (data,label) in enumerate(tqdm(self.test_dataloader)):\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "            # prediction model\n",
        "            output = self.model(data)\n",
        "            # find loss\n",
        "            loss = self.criterion(output, label)\n",
        "            n_corrects = (output.argmax(axis=1)==label).sum().item()\n",
        "\n",
        "            sum_loss += loss.item()\n",
        "            sum_accuracy += n_corrects/label.size(0)\n",
        "\n",
        "        val_loss = sum_loss/n\n",
        "        val_accuracy = sum_accuracy/n\n",
        "\n",
        "        self.history['val_loss'].append(val_loss)\n",
        "        self.history['val_acc'].append(val_accuracy)\n",
        "\n",
        "        return val_loss, val_accuracy\n",
        "\n",
        "    def train(self):\n",
        "        for epoch in range(num_epochs):\n",
        "            train_loss, train_acc = self.train_loop()\n",
        "            val_loss, val_acc = self.validation_loop()\n",
        "            print()\n",
        "            print(f'Epoch[{epoch+1}/{num_epochs}] \\t train_loss: {train_loss:.5f}, train_acc: {train_acc:.2f} \\t val_loss: {val_loss:.5f} \\t val_acc: {val_acc:.2}')\n"
      ],
      "metadata": {
        "id": "CCn78OVRyEvV"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model.to(device),\n",
        "    train_dataloader = train_data,\n",
        "    test_dataloader = test_data,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer\n",
        ")"
      ],
      "metadata": {
        "id": "wqLTDKKmyHi-"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nT_LgCYyJy2",
        "outputId": "10a8e85a-7ce3-4ac5-9654-6df677e9db17"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.98it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch[1/5] \t train_loss: 9.11578, train_acc: 0.72 \t val_loss: 0.90843 \t val_acc: 0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:03<00:00,  5.41it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch[2/5] \t train_loss: 1.70458, train_acc: 0.93 \t val_loss: 1.06035 \t val_acc: 0.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.75it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch[3/5] \t train_loss: 0.49775, train_acc: 0.98 \t val_loss: 0.02024 \t val_acc: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.82it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch[4/5] \t train_loss: 0.49091, train_acc: 0.97 \t val_loss: 0.01140 \t val_acc: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:03<00:00,  5.51it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch[5/5] \t train_loss: 0.32906, train_acc: 0.98 \t val_loss: 5.58698 \t val_acc: 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_img,test_label=next(iter(test_data))\n",
        "pred=model(test_img.to(device))\n",
        "pred=pred.argmax(axis=1)\n",
        "pred = pred.detach().cpu()\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print( test_label)\n",
        "cm=confusion_matrix(test_label,pred)\n",
        "print(cm)\n",
        "import seaborn as sns\n",
        "sns.heatmap(cm,annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "hdUNwU0syPKl",
        "outputId": "4449f236-8259-4177-dcb8-1c70587120c6"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "[[0 0]\n",
            " [3 7]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -O dataset.zip https://www.dropbox.com/s/fdlnoh5stmumy0d/Kompiyuter.zip?dl=0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds94rdnyBOow",
        "outputId": "babf349d-056e-4cc7-87ba-9da44ec2881c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-09 16:43:41--  https://www.dropbox.com/s/fdlnoh5stmumy0d/Kompiyuter.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6027:18::a27d:4812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/fdlnoh5stmumy0d/Kompiyuter.zip [following]\n",
            "--2023-07-09 16:43:42--  https://www.dropbox.com/s/raw/fdlnoh5stmumy0d/Kompiyuter.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc4c1c0fc08c9686e5f9c083bbd9.dl.dropboxusercontent.com/cd/0/inline/B_hujwHuVCcvoAxhf8y6581MCvaCEIplYtkvSWp90_RAyzA1lZHJaPz-Z_ZyMZc9GTkcsKL7T96mFFtQgJiiTPL0odaPUxfXaGrnpzpxlnVUkMDMZZihM5FbL24WjTHeM0TKrsPBuya4GMaVe957_OdZ_RDHuhwgSAJqZdwiwjO1dA/file# [following]\n",
            "--2023-07-09 16:43:42--  https://uc4c1c0fc08c9686e5f9c083bbd9.dl.dropboxusercontent.com/cd/0/inline/B_hujwHuVCcvoAxhf8y6581MCvaCEIplYtkvSWp90_RAyzA1lZHJaPz-Z_ZyMZc9GTkcsKL7T96mFFtQgJiiTPL0odaPUxfXaGrnpzpxlnVUkMDMZZihM5FbL24WjTHeM0TKrsPBuya4GMaVe957_OdZ_RDHuhwgSAJqZdwiwjO1dA/file\n",
            "Resolving uc4c1c0fc08c9686e5f9c083bbd9.dl.dropboxusercontent.com (uc4c1c0fc08c9686e5f9c083bbd9.dl.dropboxusercontent.com)... 162.125.66.15, 2620:100:6027:15::a27d:480f\n",
            "Connecting to uc4c1c0fc08c9686e5f9c083bbd9.dl.dropboxusercontent.com (uc4c1c0fc08c9686e5f9c083bbd9.dl.dropboxusercontent.com)|162.125.66.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B_h-WxdYYyEl-fRo5Sf5CQCeSV2wK2WtK3kHkbxbY_r-q9or68RYz--PJy4jPJUiA5KW3XudjOjkjFCZ7N1QrBhuclv6LXSIS4NeOwF7vWk7oYdm5GkMjDmEAq_Q-ArIfcnZgrRSrg-zY_9hKBKYGJ674Cm65j_BlH0mO0L8iiQ1Wtsmc_FdzYy-0I_FwGtusMEsdZeL2v9br2jboq_up2JNnz5OLxFTehioAiva3LqGiObBnC2Ak-e-tDdM8N4yweDDwLwen5mk7AoKRXpIz6t6EV7Dh-VkB8SIRDot8ExW_t8rBPlV0Es8MUKRAUdF9kVOPrz6IPrZllRhhirws0yDhN_hXVSAikZIvb3FfEZx5sxsdpePCFbAOphqLliCIHObhG3XrkARSEgljy53gu3nbmrFNIpH2z2fsEnbplBkRw/file [following]\n",
            "--2023-07-09 16:43:42--  https://uc4c1c0fc08c9686e5f9c083bbd9.dl.dropboxusercontent.com/cd/0/inline2/B_h-WxdYYyEl-fRo5Sf5CQCeSV2wK2WtK3kHkbxbY_r-q9or68RYz--PJy4jPJUiA5KW3XudjOjkjFCZ7N1QrBhuclv6LXSIS4NeOwF7vWk7oYdm5GkMjDmEAq_Q-ArIfcnZgrRSrg-zY_9hKBKYGJ674Cm65j_BlH0mO0L8iiQ1Wtsmc_FdzYy-0I_FwGtusMEsdZeL2v9br2jboq_up2JNnz5OLxFTehioAiva3LqGiObBnC2Ak-e-tDdM8N4yweDDwLwen5mk7AoKRXpIz6t6EV7Dh-VkB8SIRDot8ExW_t8rBPlV0Es8MUKRAUdF9kVOPrz6IPrZllRhhirws0yDhN_hXVSAikZIvb3FfEZx5sxsdpePCFbAOphqLliCIHObhG3XrkARSEgljy53gu3nbmrFNIpH2z2fsEnbplBkRw/file\n",
            "Reusing existing connection to uc4c1c0fc08c9686e5f9c083bbd9.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 865265 (845K) [application/zip]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip         100%[===================>] 844.99K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-07-09 16:43:43 (6.12 MB/s) - ‘dataset.zip’ saved [865265/865265]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset.zip"
      ],
      "metadata": {
        "id": "YfFaV3lTBZdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "6zBwzk-CBeit"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Compose([\n",
        "    T.Resize(size=(150,150)),\n",
        "    T.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "bd-LCNCABhbQ"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KompyuterDataset(Dataset):\n",
        "\n",
        "    def __init__(self, path, transform = None):\n",
        "        # int for cross entryp loss\n",
        "        self.path_list = list(path.glob('*/*.jpg'))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        img = Image.open(self.path_list[index])\n",
        "        label = (self.path_list[index]).parts[-2]\n",
        "        label = 0 if 'kompiyuter' in label else 1\n",
        "        if transform != None:\n",
        "            img = transform(img)\n",
        "\n",
        "        return img, int(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.path_list)"
      ],
      "metadata": {
        "id": "NtBVuoH6Bkuf"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = pathlib.Path('/content/Kompiyuter/train')\n",
        "test_path = pathlib.Path('/content/Kompiyuter/validation')"
      ],
      "metadata": {
        "id": "ArV10cESBrZS"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = KompyuterDataset(train_path, transform)\n",
        "test_dataset = KompyuterDataset(test_path, transform)"
      ],
      "metadata": {
        "id": "u6mDrx4gB2bp"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_list = list(train_path.glob('*/*.jpg'))\n",
        "path_test=list(test_path.glob('*/*.jpg'))"
      ],
      "metadata": {
        "id": "q80wBAFZB51A"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
        "test_data = DataLoader(test_dataset, batch_size=10, shuffle=True)"
      ],
      "metadata": {
        "id": "15a-2rGPB9Ns"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self,num_classes=2):\n",
        "        super(ConvNet,self).__init__()\n",
        "\n",
        "        #Output size after convolution filter\n",
        "        #((w-f+2P)/s) +1\n",
        "\n",
        "        #Input shape= (256,3,150,150)\n",
        "\n",
        "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,12,150,150)\n",
        "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
        "        #Shape= (256,12,150,150)\n",
        "        self.relu1=nn.ReLU()\n",
        "        #Shape= (256,12,150,150)\n",
        "\n",
        "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
        "        #Reduce the image size be factor 2\n",
        "        #Shape= (256,12,75,75)\n",
        "\n",
        "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,20,75,75)\n",
        "        self.relu2=nn.ReLU()\n",
        "        #Shape= (256,20,75,75)\n",
        "\n",
        "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,32,75,75)\n",
        "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
        "        #Shape= (256,32,75,75)\n",
        "        self.relu3=nn.ReLU()\n",
        "        #Shape= (256,32,75,75)\n",
        "\n",
        "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
        "\n",
        "        #Feed forwad function\n",
        "\n",
        "    def forward(self,input):\n",
        "        output=self.conv1(input)\n",
        "        output=self.bn1(output)\n",
        "        output=self.relu1(output)\n",
        "\n",
        "        output=self.pool(output)\n",
        "\n",
        "        output=self.conv2(output)\n",
        "        output=self.relu2(output)\n",
        "\n",
        "        output=self.conv3(output)\n",
        "        output=self.bn3(output)\n",
        "        output=self.relu3(output)\n",
        "\n",
        "        #Above output will be in matrix form, with shape (256,32,75,75)\n",
        "\n",
        "        output=output.view(-1,32*75*75)\n",
        "\n",
        "        output=self.fc(output)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "wsWOohFRCAq-"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=ConvNet()"
      ],
      "metadata": {
        "id": "w8dRQ3ONCDov"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "XAKd-6SWCGOZ"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5"
      ],
      "metadata": {
        "id": "kJQKM3I5CJNw"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, train_dataloader, test_dataloader, criterion, optimizer, epochs=3):\n",
        "        self.model = model\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.test_dataloader = test_dataloader\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        self.epochs = epochs\n",
        "        self.history = {'loss':[],'acc':[],'val_loss':[],'val_acc':[]}\n",
        "\n",
        "    def train_loop(self):\n",
        "        sum_loss = 0\n",
        "        sum_accuracy = 0\n",
        "        n = len(self.train_dataloader)\n",
        "        for i, (data,label) in enumerate(tqdm(self.train_dataloader)):\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "            # prediction model\n",
        "            output = self.model(data)\n",
        "            # find loss\n",
        "            loss = self.criterion(output, label)\n",
        "\n",
        "            sum_loss += loss.item()\n",
        "            n_corrects = (output.argmax(axis=1)==label).sum().item()\n",
        "            sum_accuracy += n_corrects/label.size(0)\n",
        "\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        train_loss = sum_loss/n\n",
        "        train_accuracy = sum_accuracy/n\n",
        "\n",
        "        self.history['loss'].append(train_loss)\n",
        "        self.history['acc'].append(train_accuracy)\n",
        "\n",
        "        return train_loss, train_accuracy\n",
        "\n",
        "    def validation_loop(self):\n",
        "        sum_loss = 0\n",
        "        sum_accuracy = 0\n",
        "        n = len(self.test_dataloader)\n",
        "        for i, (data,label) in enumerate(tqdm(self.test_dataloader)):\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "            # prediction model\n",
        "            output = self.model(data)\n",
        "            # find loss\n",
        "            loss = self.criterion(output, label)\n",
        "            n_corrects = (output.argmax(axis=1)==label).sum().item()\n",
        "\n",
        "            sum_loss += loss.item()\n",
        "            sum_accuracy += n_corrects/label.size(0)\n",
        "\n",
        "        val_loss = sum_loss/n\n",
        "        val_accuracy = sum_accuracy/n\n",
        "\n",
        "        self.history['val_loss'].append(val_loss)\n",
        "        self.history['val_acc'].append(val_accuracy)\n",
        "\n",
        "        return val_loss, val_accuracy\n",
        "\n",
        "    def train(self):\n",
        "        for epoch in range(num_epochs):\n",
        "            train_loss, train_acc = self.train_loop()\n",
        "            val_loss, val_acc = self.validation_loop()\n",
        "            print()\n",
        "            print(f'Epoch[{epoch+1}/{num_epochs}] \\t train_loss: {train_loss:.5f}, train_acc: {train_acc:.2f} \\t val_loss: {val_loss:.5f} \\t val_acc: {val_acc:.2}')\n"
      ],
      "metadata": {
        "id": "DTeiwZVJCMCu"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model.to(device),\n",
        "    train_dataloader = train_data,\n",
        "    test_dataloader = test_data,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer\n",
        ")"
      ],
      "metadata": {
        "id": "3IQN7YtHCPC3"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrRMzS27CSys",
        "outputId": "8c528af7-2b6f-49b4-c2e0-83985d8afd80"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  5.14it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  9.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch[1/5] \t train_loss: 1.88420, train_acc: 0.94 \t val_loss: 12.72379 \t val_acc: 0.65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:08<00:00,  1.25it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch[2/5] \t train_loss: 0.88480, train_acc: 0.97 \t val_loss: 7.60129 \t val_acc: 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  4.72it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  9.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch[3/5] \t train_loss: 0.00009, train_acc: 1.00 \t val_loss: 11.77107 \t val_acc: 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:07<00:00,  1.30it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  9.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch[4/5] \t train_loss: 0.20016, train_acc: 0.99 \t val_loss: 7.92817 \t val_acc: 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  4.28it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  9.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch[5/5] \t train_loss: 0.00000, train_acc: 1.00 \t val_loss: 6.04412 \t val_acc: 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_img,test_label=next(iter(test_data))\n",
        "pred=model(test_img.to(device))\n",
        "pred=pred.argmax(axis=1)\n",
        "pred = pred.detach().cpu()\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print( test_label)\n",
        "cm=confusion_matrix(test_label,pred)\n",
        "print(cm)\n",
        "import seaborn as sns\n",
        "sns.heatmap(cm,annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "YW760-ZaCrzm",
        "outputId": "7cb2b2d9-6fa2-4ae3-f8f0-dad9aaa2a7a3"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 0, 1, 1, 0, 0, 1, 0, 0, 0])\n",
            "[[5 1]\n",
            " [1 3]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}